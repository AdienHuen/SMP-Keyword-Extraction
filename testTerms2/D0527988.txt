#快速/d视频/gi图像/gi上/f采样/gi
摘要/n    /x我们/rr提出/v了/ule一种/nz简单/a而/cc高效/b的/ude1上/f采样/gi方法/gi。/w这种/r方法/gi能够/v自动/d的/ude1增强/v视频/gi图像/gi的/ude1分辨率/n，/w同时/c能够/v保持/v图像/gi的/ude1重要/a结构/gi信息/gi。/w我们/rr的/ude1方法/gi主要/b优点/gi在于/v一个/mq反馈/gi控制/vn框架/gi，/w这个/rz框架/gi能够/v从/p低分辨率/n图像/gi确切/a地/ude2复原/vi高分辨率/nz图像/gi，/w而/cc不/d需要/v强加/vi从/p其它/rz样本/gi中/f学习/gi到/v的/ude1图像/gi的/ude1局部/n结构/gi约束/gi信息/gi。/w这/rzv使得/vi我们/rr的/ude1方法/gi在/p图像质量/gi上/f与/cc通过/p大量/m采样/gi学习/gi得到/v的/ude1高质量/nz图像/gi是/vshi独立/a的/ude1。/w通常/d大量/m样本/gi学习/gi的/ude1算法/gi，/w能够/v产生/v高质量/nz的/ude1图像质量/gi而/cc没有/v可/v觉察/v到/v的/ude1难看/a的/ude1人工/b痕迹/n。/w我们/rr的/ude1方法/gi另外/c一个/mq优点/gi是/vshi可以/v很/d自然地/nz扩展到/v视频/gi的/ude1上/f采样/gi中/f，/w同时/c，/w视频/gi的/ude1暂态/nz连续性/n能够/v自动/d的/ude1保持/v。/w最后/f，/w我们/rr的/ude1算法/gi运行/gi的/ude1很快/d。/w我们/rr通过/p不同/a的/ude1视频/gi图像/gi数据/gi演示/gi了/ule我们/rr的/ude1算法/gi的/ude1有效性/gi。/w /x注/v：/w本文/r系/v我/rr10/nz年/qt翻译/gi的/ude1香港中文大学/nt贾佳亚/nz发表/v在/psiggraph asia /nz2008/nz的/ude1文章/gi，/w很/d多/a地方/n翻译/gi的/ude1不好/a，/w敬请/v见谅/vi。/w    /x翻译稿/nz请/v从/p这里/rzs下载/gi。/w       /x原文/n下载/gi地址/gi：/w    /x他们/rr的/ude1处理结果/n显示/gi，/w上/f采样/gi效果/gi相当/d不错/a，/w他们/rr宣称/v可以/v实时处理/gi视频/gi。/w但/c在/p没有/vgpu/gi的/ude1情况下/nz很慢/d很慢/d，/w在/p我/rr的/ude1pc/nz机上/s测试/gi，/w对/p720/nzp/nz的/ude1图片/gi放大/v2/nz倍/q都/d要数/n10/nz秒/qt。/w    /x参照/v他们/rr的/ude1思路/gi，/w我/rr用/p基于/p稀疏/a先验/n分布/vi的/ude1反卷/nz积/v算法/gi实现/gi了/ule一下/m，/w实际效果/n没有/v他们/rr的/ude1好/a，/w但/c比/pbicubic/nz要好/a。/w而/cc他们/rr的/ude1处理/vn效果/gi，/w比/pbicubic/nz明显/a的/ude1好/a出/vf许多/m，/w他们/rr的/ude1测试/gi图/gi如下/vi：/w              /x