#照片/n的/ude1OCR/nz识别/gi
来自/vng/nz的/ude1ml/nz-/nz003/nz中/f18/nz_/nzxviii/nz./nz_/nzapplication/nz_/nzexample/nz-/nz_/nzphoto/nz_/nzocr/gi这/rzv是/vshing/nz2013/nz年/qt在/pcoursera/nz上/f最后/f的/ude1一课/nz了/ule。/w这/rzv一系列/b的/ude1几个/nz视频/gi还是/c相比/vi前面/f有些/rz难懂/a，/w。。。。。。/wng/nz说/v拿/v这个/rz做/v例子/gi有/vyou三个/nz原因/n：/w一/nz、/w演示/gi如何/ryv将/d复杂/a的/ude1机器学习/gi进行/vn融合/v；/w二介绍/nz下/f机器学习/gi的/ude1type line/gi和/cc当/p你/rr决定/v做/v某事/r的/ude1时候/n如何/ryv的/ude1利用/v资源/gi；/w三/nz、/w这个/rz例子/gi能够/v说明/v更多/ad有趣/a的/ude1机器学习/giidea/gi（/w将/d机器学习/gi用于/v计算机视觉/gi，/w人工/b数据/gi综合/vn）/w首先/d是/vshi图像/gi中的/v文字识别/gi这/rzv是/vshi最简单/nz的/ude1几部/n划分/v，/w（/w但是/c比如/v你/rr之前/f的/ude1单词/gi是/vshicleaning/nz，/w但是/c机器/gi有/vyou可能会/nz反馈/gi给/p你/rrc1/gieaning/nz，/w会/v有/vyou少许/mq的/ude1错误/gi，/w简单/a的/ude1提下/v）/w这里/rzs是/vshi一个/mqocr/gi识别/gi的/ude1管道/n图/gi，/w下面/f是/vshi每个/r部分/n差不多/al需要/v这么/rz多/a人/n的/ude1合作/vn，/w但是/c（/wng/nz最后/f居然/d说/v其实/d一/nz个人/n完成/v整个/b工作/gi也/d是/vshi可以/v的/ude1，/w如果/c他/rr知道/v怎么做/nz的话/udh，/w唉/e）/w一/nz、/w滑动/vi窗口/s相/d对应/vi来说/uls，/w行人/n检测/gi中的/v窗口/s比较简单/l，/w因为/c他/rr的/ude1背景/n较为/d单一/gi，/w不/d像/v之前/f的/ude1文本/gi识别/gi，/w背景/n很/d是/vshi复杂/a，/w在行/a人/n检测/gi中/f，/w要/v考虑到/v不同/a距离/gi下/f不同/a人/n的/ude1窗口/s的/ude1高度/d和/cc宽度/n等等/udeng。/w这里/rzs是/vshi个/q简单/a的/ude1数据集/nz的/ude1例子/gi，/w通过观察/l采用/v这么/rz大/a的/ude1窗口/s较为/d合适/a，/w行人/n检测/gi的/ude1数据/gi集/q一般/ad都/d是/vshi1/nzk/nz或者/c10/nzk/nz等等/udeng的/ude1从/p图/gi的/ude1左上角/nz开始/v一个/mq82/nz*/nz36/nz的/ude1窗口/s，/w然后/c分类/gi获得/v这个/rz是/vshiy/nz=/nz0/nz，/w就是/v非/b行人/n的/ude1数据/gi，/w然后/c将/d窗口/s右移/gi这/rzv其中/rz的/ude1移动/vn的/ude1距离/gi就/d叫做/vstepsize/nz，/w如果/cstepsize/nz等于/v1/nz /x的确/d可以/v抓取/gi足够/v的/ude1数据/gi，/w但是/c计算/gi量/n太大/d，/w一半/mq都/d是/vshistepsize/nz等于/v4/nz /x或者/c8./nz然后/c这里/rzs的/ude1窗口/s大小/n如果/c按照/p需要/v也/d是/vshi可以/v调/v的/ude1更大/d的/ude1。/w并/cc不是/c完全/ad的/ude1限定/v在/p一个数/nz上/f这样/rzv就/d能够/v获得/v这样/rzv一个/mq结果/n通过/p这样/rzv的/ude1方法/gi就/d能/v应用/gi在/p文字识别/gi上/f，/w通过/p不同/a的/ude1滑动/vi窗口/s获得/v文本/gi的/ude1位置/gi通过/p不同/a的/ude1滑动/vi窗口/s最后/f就/d锁定/v了/ule文字/gi的/ude1位置/gi，/w然后/c进行/vn图片/gi的/ude1放大/v来/vf更/d清晰/a的/ude1显示/gi字符串/gi的/ude1位置/gi但是/c如果/c采用/v中间/f划分/v的/ude1方法/gi，/w左边/f的/ude1明显/a是/vshi滑动/vi窗口/s取到/v了/ule两/nz个/q字/n，/w而/cc右边/f的/ude1是/vshi取到/v了/ule一个/mq完整/a的/ude1字/n通过/p一种/nz方法/gi当/p滑动/vi窗口/s滑倒/nz完整/a的/ude1字/n的/ude1时候/n不/d采用/v切分/v，/w而/cc滑倒/nz两/nz个/q字/n的/ude1时候/n采用/v切分。二/nz、/w人工/b数据/gi结合/vng/nz说/v见过/v的/ude1最好/d的/ude1机器学习/gi算法/gi都/d是/vshi采用/v一个/mqlow bias/nz算法/gi，/w然后/c再/d大量/m的/ude1数据/gi上/f运行/gi。/w对于/p文字识别/gi来说/uls。/w数据/gi有/vyou一个/mq是/vshi来自/v于/p真实/a的/ude1数据/gi，/w一个/mq是/vshi来自/v于/p众多/a的/ude1字体库/nz或者/c通过/p采用/v字体库/nz的/ude1字体/gi，/w在/p放到/v实际/n数据/gi的/ude1背景/n上/f合成/gi人工/b数据/gi：/w或者/c是/vshi在/p数据/gi上/f加上/v扭曲/vi等/udeng方法/gi在/p音频/gi上/f：/w对于/p数据/gi添加/gi噪声/n来说/uls，/w添加/gi的/ude1噪声/n是/vshi有/vyou意义/n的/ude1，/w比如/v上/f图/gi中的/v扭曲/vi是/vshi可以/v在/ptest/nz中/f真实/a找到/v的/ude1，/w（/w类/gi模拟/gitest/nz数据/gi一样/uyy）/w。/w而/cc下文/n中的/v椒盐/n噪声/n是/vshi无/v意义/n的/ude1，/w添加/gi了/ule也/d没什么/vl帮助/v，/w因为/c在/p这个/rz例子/gi中/f，/w我们/rr是/vshi想/v识别/gi的/ude1文字/gi而且/c文字/gi的/ude1扭曲/vi是/vshi真实世界/gi中/f看得/v到/v的/ude1，/w而/cc添加/gi的/ude1椒盐/n噪声/n是/vshi除非/c你/rr就是/v为了/p比如/v降噪/vi这种/r噪音/n，/w能够/v在/ptest/nz中/f看到/v的/ude1，/w因为/c这里/rzs是/vshi为了/p识别/gi不同/a形状/n的/ude1a/nz，/w而/cc不是/c为了/p降噪/vi，/w按照/p上/f图说/n的/ude1，/w在/p添加/gi人工合成/nz的/ude1数据/gi的/ude1时候/n，/w一定/b要/v知道/v你/rr的/ude1模型/gi是不是/v过/uguo拟合/gi的/ude1，/w如果/c模型/gi是/vshi欠/v拟合/gi的/ude1，/w那么/c增加/v再多/d的/ude1数据/gi都/d是/vshi在/p浪费时间/nz。/w其次/c，/w可以/v坐/v下来/vf和/cc团队/gi的/ude1人员/gi一起/s问问/v /x想要/v这些/rz数据/gi的/ude1处理速度/n提升/gi10/nzx/nz，/w需要/v做/v多少/ry工作/gi：/w1/nz、/w人工合成/nz；/w2/nz、/w手动/b添加/gi标签/gi；/w3/nz、/w寻找/v混合/vn来源/gi。/w三/nz、/w细胞/n级别/n分析/gi如上图/i来说/uls，/w对于/p整个/b系统/gi而言/uls，/w每个/r地方/n都/d是/vshi需要/v做/v工作/gi的/ude1，/w但是/c如何/ryv找到/v这个/rz系统/gi的/ude1瓶颈/gi之处/r，/w通过/p提升/gi这个/rz系统/gi的/ude1瓶颈/gi来/vf达到/v提升/gi整个/b系统/gi的/ude1效率/gi，/w这/rzv是/vshi得/ude3思考/gi的/ude1，/w不然/c在/p其他/rzv表现/v很好/ad的/ude1环节/gi上/f大量/m的/ude1工作/gi，/w最后/f还是/c在/p浪费时间/nz相比较/nz而言/uls，/w首先/d没有/v任何/rz改变/v的/ude1情况下/nz最好/d的/ude1精度/n是/vshi72%/nz，/w然后/c通过/p修改/gi第二项/nz，/w让/v他/rr的/ude1输出/gi是/vshi100/nz准确/a的/ude1，/w那么/c整个/b系统/gi提升/gi到/v89%/nz的/ude1精度/n，/w有/vyou17%/nz的/ude1改变/v，/w说明/v这部/r分得/v我们/rr花/n时间/gi，/w然后/c再/d改动/vn第二项/nz的/ude1基础上/nz，/w接着/c将/d第三项/nz改动/vn成/v完美/a情况下/nz，/w整个/b系统/gi只/d提升/gi了/ule1%/nz，/w这/rzv说明/v第三项/nz是/vshi很好/ad的/ude1，/w差不多/al不/d需要/v花/n时间/gi去/vf完善/v。/w这/rzv同样/d让/v我们/rr知道/v每个/r部分/n的/ude1上限/n是/vshi多少/ry，/w和/cc在/p这个/rz部分/n的/ude1上限/n上/f运行/gi的/ude1时候/n整个/b系统/gi的/ude1精度/n是/vshi多少/ry上面/f两/nz个/q图/gi就是/v一/nz个人/n脸/n检测/gi的/ude1模型/gi过程/gi。/w通过/p与/cc最/d原始/a的/ude1模型/gi的/ude1效果/gi相对/d比/p，/w先/d逐个/d部分/n的/ude1进行/vn人工/b的/ude1修改/gi（/w即将/d这个/rz部分/n的/ude1精度/n提到/v上限/n）/w，/w比如/v第一/mq部分/n的/ude1背景/n移除/v，/w可以/v通过/pps/nz等/udeng软件/gi人工/b的/ude1去除/v，/w然后/c将/d这个/rz完美/a的/ude1模型/gi代替/v第一/mq部分/n的/ude1输出/gi，/w观察/gi整个/b模型/gi提升/gi的/ude1效果/gi，/w这里/rzs第一个/gi模型/gi只/d提升/gi了/ule0.1%/nz，/w说明/v这/rzv部分/n没什么/vl可/v改善/v的/ude1地方/n。/w接着/c往/p下/f按照/p这种/r原理/gi进行/vn。/w找到/v整个/b模型/gi的/ude1瓶颈/gi之处/r。/w就是/v用/p人工/b的/ude1小数据/gi去/vf验证/v模型/gi的/ude1瓶颈/gi，/w而/cc不至于/d花/n了/ule很久/d时间/gi才/d发现/v其实/d都/d在/p浪费时间/nz。/w