#Andrew/gi机器学习/gi课程/gi笔记/gi（/w6/nz）/w[/nzEnd/nz]/nz―/w―/w /x机器学习/gi的/ude1一个/mq应用/gi实例/gi
课程/gi最后/f以/p一个/mq图像/giocr/gi的/ude1例子/gi作为/p结束/v，/wocr/gi技术/gi本身/rz讨论/gi的/ude1不/d多/a（/w毕竟/d不是/c图像处理/gi课程/gi）/w，/w但/c围绕/v该/rz实例/gi涉及/v到/v的/ude1训练数据/gi获取/gi和/cc机器学习/gi项目/gi的/ude1上限/n分析/gi还是/c很/d有/vyou意义/n的/ude1本/rz节/q讨论/gi以下三/nz个/q问题/gi：/w图像/giocr/gi的/ude1基本/a步骤/gi、/w机器学习/gi训练数据/gi的/ude1获取/gi、/w上限/n分析/gi图像/giocr/gi的/ude1基本/a步骤/gi图像/gi文字识别/gi涉及/v到/v的/ude1工作/gi主要/b分为/v：/w文本/gi检测/gi、/w字符/gi分割/gi、/w字符识别/gp图/gi1/nz-/nz1./nz /x图像/giocr/gi的/ude1基本/a步骤/gi（/w图片/gi来源/gi：/w课程/gi视频/gi）/w文本/gi检测/gi使用/gi滑动/vi窗口/s的/ude1方式/n，/w根据/p目标/gi的/ude1长宽/v比/p预设/v窗口/s的/ude1尺寸/gi，/w在/p待/vi检/ng图片/gi上/f滑动/vi，/w求出/v每个/r区域/n的/ude1概率/gi图/gi1/nz-/nz2./nz /x文本/gi检测/gi（/w图片/gi来源/gi：/w课程/gi视频/gi）/w然后/c对/p图/gi1/nz-/nz2/nz右/f做/v膨胀/vi，/w按照/p一定/b的/ude1长宽/v做/v筛选/v便/d得到/v最终/d的/ude1文本/gi位置/gi了/ule字符/gi分割/gi课程/gi中/f还是/c用/p了/ule文本/gi检测/gi的/ude1模板匹配/gi的/ude1方式/n（/w虽然/c我/rr的/ude1直觉/n是/vshi用/p联通/v域/ng的/ude1方法/gi）/w：/w首先/d准备/v一/nz些/q字符/gi与/cc字符/gi间隔/n的/ude1图片/gi作为/p模板/gi，/w然后/c在/p待/vi检/ng区域内/nz滑动/vi，/w匹配/gi的/ude1位置/gi从/p中间/f做/v分割图/nz1/nz-/nz3./nz /x字符/gi分割/gi（/w图片/gi来源/gi：/w课程/gi视频/gi）/w，/w图/gi上/f部分/n是/vshi模板/gi，/w下/f部分/n是/vshi滑动/vi分割/gi过程/gi字符识别/gp就/d有/vyou很/d多方法/nz了/ule，/w总体/n来说/uls就是/v准备/v足够/v数量/n与/cc种类/n的/ude1正负/b样本/gi，/w丢到/nz分类器/n里/f训练/gi，/w然后/c拿出/v来/vf做/v分类/gi训练数据/gi的/ude1获取/gi对于/p一个/mq机器学习/gi算法/gi，/w理论上/nz来说/uls训练样本/n越多/ad，/w覆盖面/n越/d广/a，/w得到/v的/ude1模型/gi就/d越好/d（/w当然/d在/p决定/v扩展/gi训练数据/gi之前/f还是/c需要/v评估/gi下/f目前/t模型/gi是否/v为/p过/uguo拟合/gi）/w扩展/gi训练数据/gi最/d直接/ad的/ude1方法/gi当然/d是/vshi去/vf网上/s找/v咯/y，/w但/c很/d多/a情况下/nz可能/v网上/s并/cc没有/v符合/v自己/rr需求/gi的/ude1样本/gi。/w这个/rz时候/n就/d需要/v自己/rr合成/gi一/nz些/q数据/gi了/ule人工合成/nz训练样本/n有/vyou两/nz种/q方式/n：/w再/d创作/vn（/w对于/p字符识别/gp，/w可以/v利用/v不同/a的/ude1字体/gi与/cc不同/a的/ude1背景/n做/v排列组合/nz，/w生成/v新/a样本/gi）/w；/w对/p现有/v样本/gi做/v修饰/v（/w扭曲/vi、/w旋转/gi、/w加/v噪声/n。。。/w）/w上限/n分析/gi以图/v1/nz-/nz1/nz为/p例/n，/w对于/p一个/mq初步/d的/ude1图像/gi文字识别/gi算法/gi，/w现在/t想要/v提升/gi它/rr的/ude1识别/gi精度/n，/w那么/c我们/rr需要/v在/p文本/gi检测/gi、/w字符/gi分割/gi和/cc字符识别/gp中的/v哪个/ry下/f大/a功夫/n呢/y？/w这个/rz问题/gi可以/v等/udeng价/n为/p分析/gi当前/t整体/n算法/gi的/ude1性能/gi瓶颈/gi，/w就是/v上限/n分析/gi啦/y上限/n分析/gi的/ude1思路/gi很/d简单/a，/w以图/v1/nz-/nz1/nz为/p例/n：/w1./nz /x首先/d通过/p人工干预/gi（/w把/pba文本/gi准确/a位置/gi告诉/v算法/gi）/w确保/v文本/gi检测/gi的/ude1精度/n是/vshi100%/nz，/w看/v这种/r情况下/nz整体/n算法/gi的/ude1精度/n提升/gi多少/ry2./nz /x然后/c保持/v文本/gi检测/gi精度/n100%/nz，/w确保/v字符/gi分割/gi精度/n为/p100%/nz，/w看/v这种/r情况下/nz整体/n算法/gi的/ude1精度/n提升/gi多少/ry3./nz /x最后/f保持/v三项/nz精度/n都/d为/p100%/nz，/w看/v整体/n算法/gi的/ude1精度/n提升/gi4./nz /x比较/gi3/nz个/q精度/n提升/gi，/w最大/gm的/ude1表示/v对应/vi的/ude1那/rzv一步/nz是/vshi目前/t最/d影响/gi算法/gi整体/n精度/n的/ude1图/gi1/nz-/nz4./nz /x图像/giocr/gi的/ude1上限/n分析/gi（/w图片/gi来源/gi：/w课程/gi视频/gi）/w图/gi1/nz-/nz4/nz所示/nz的/ude13/nz个/q精度/n提升/gi分别为/v：/w17%/nz、/w1%/nz、/w10%/nz，/w所以/c应该/v着重/vd考虑/v文本/gi检测/gi的/ude1算法/gi。/w