#微软/ntc亚洲/ns研究院/nis对/p传统/nOCR/nz的/ude1突破/gi和/cc进展/vn（/w有/vyou详细/gi检测/gi /x识别/gi的/ude1介绍/gi）/w，/w及/cc成果/gi展示/gi
光学/gi字符识别/gp技术/gi：/w让/v电脑/gi像/v人/n一样/uyy阅读/gi　/nz文/ng//nz霍强/nz　　/nz把/pba手机/gi摄像头/gi对准/v菜单/gi上/f的/ude1法语/nz菜名/n，/w屏幕/gi上/f实时/n显示/gi出/vf翻译/gi好/a的/ude1中文/gi菜名/n；/w将/d全世界/n图书馆/nis的/ude1藏书/n转化/gi为/p电子书/gi；/w街景/n车/n游走/v于/p大街小巷/n，/w拍摄/v街景/n的/ude1同时/c也/d从/p /x街景/n图像/gi中/f自动/d提取/v文字/gi标识/n，/w让/v地图信息/n更/d丰富/a更/d准确/a…/w…/w这些/rz场景/gi的/ude1背后/f有/vyou一个/mq共同/d的/ude1关键技术/nz―/w―/wocr /nz(/nzoptical characterrecognition/nz)/nz，/w光学/gi字符识别/gp。/w　　/nzocr/gi让/v电脑/gi“读/nz”懂/nz世界/gi　　/nz鼠标/gi发明人/ndouglas engelbart/nz曾经/d针对/gi人工智能/gi的/ude1简称/vai/gi提出/v了/ule另一个/nz理念/gi―/w―/waugmented intelligence/nz，/w增强/v智能/gi。/w在/p他/rr看来/v，/w人/n已经/d足够/v聪明/a，/w我们/rr无需/v再/d去/vf复制/gi人类/gi，/w而是/c可以/v从/p更加/d实用/a的/ude1角度/n，/w将/d人类/gi的/ude1智能/gi进一步/d延伸/v，/w让/v机器/gi去/vf增强/v人/n的/ude1智能/gi。/w　　/nz智能镜/nz就是/v这样/rzv的/ude1产品/gi，/w去/vf超市/gi的/ude1时候/n带上/v一/nz副/b，/w看到/v心仪/v商品/gi上/f的/ude1文字/gi，/w自动/d搜索/gi出/vf详细信息/nz：/w生产商/nnd情况/n、/w在/p不同/a电商/gi平台/gi的/ude1价/n等等/udeng。/w让/v智能镜/nz读懂/v文/ng /x字/n的/ude1正是/vocr/gi技术/gi。/wocr/gi本质/n上/f是/vshi利用/v光学设备/n去/vf捕获/v图像/gi，/w今天/t可以/v是/vshi手机/gi、/w照相机/n，/w未来/t可以/v是/vshi智能镜/nz、/w可/v穿戴/vn设备/gi等/udeng，/w就/d像/v人/n的/ude1睛/ng一样/uyy，/w只要/c有/vyou文/ng /x字/n，/w就/d去/vf认出来/v。/w　　/nz我们/rr也/d可以/v设想/vn一下/mocr/gi在/p未来/t工作/gi中的/v应用场景/gi：/w每次/r工作/gi会议/gi后/f，/w无需/v再/d把/pba白板/nz上/f的/ude1讨论/gi内容/gi抄写/v下来/vf，/w然后/c群发/v邮件/n布置任务/n，/w只要/c将/d白板/nz用/p手机/gi等/udeng智能设备/gi拍照/gi留存/v，/w系统/gi便/d能/v自动识别/nz并/cc分/qt检出/nz相关/vn人员/gi的/ude1后续/vn工作/gi，/w并/cc将/d待办/v事项/n自动/d存放/v到/v各自/rr的/ude1电子/gi日历/n中/f。/w　　/nz事实上/bl，/w我们/rr已经/d向/p这个/rz场景/gi迈进/vi了/ule一步/nz，/w微软/ntc前/f不久/d推出/v的/ude1office lens/nz应用/gi，/w已经/d可以/v通过/p视觉/n计算/gi技术/gi自动/d对/p图像/gi进行/vn清理/gi并/cc把/pba它/rr保存/gi到/vonenote/nz，/w而/cconenote/nz中/f基于/p云端/n的/ude1ocr/gi技术/gi将/d对/p图片/gi进行/vn文字识别/gi，/w /x随后/d你/rr就/d可以/v拥有/v一个/mq可/v编辑/gi、/w可/v搜索/gi的/ude1数字/gi文件/gi，/w为/p上述/b未来/t应用场景/gi打下基础/l。/w微软/ntc几年前/nz推出/v的/ude1手机/gi应用/gitranslator/nz，/w除了/p支持/v文本/gi和/cc语音/gi翻译/gi /x外/f，/w还/d能用/v手机/gi拍摄/v不同/a语言/gi的/ude1菜单/gi或/c指示牌/nz，/w翻译/gi结果/n立即/d浮现/vi于/p原文/n之上/f。/woffice lens/nz和/cctranslator/nz这/rzv两/nz款/q产品/gi中的/v“/w中日韩/ns”/wocr/gi核心技术/nz就/d来自/v的/ude1语音/gi团队/gi。/w从/p平板/n扫描仪/gi到/v前端/gi手机/gi后端/f云/gi　　/nz回过/v头/n来看/u，/wocr/gi技术/gi经历/gi了/ule怎样/ryv的/ude1发展/gi历程/gi呢/y？/w早/a在/p20/nz世纪/qt50/nz年代/n，/wibm/nz就/d开始/v利用/vocr/gi技术/gi实现/gi各类/r文档/gi的/ude1数字化/vn，/w早期/f的/ude1ocr/gi设备/gi庞大/a而复/d /x杂/a，/w只能/v处理/vn干净/a背景/n下/f的/ude1某种/rz印刷/vn字体/gi。/w20/nz世纪/qt80/nz年代/n，/w平板/n扫描仪/gi的/ude1诞生/gi让/vocr/gi进入/v商用/b阶段/gi，/w设备/gi更为/d轻便/a灵巧/a，/w可以/v处理/vn的/ude1字体/gi数量/n也/d增多/v，/w但/c对/p文/ng /x字/n的/ude1背景/n要求/n仍然/d很高/d，/w需要/v很好/ad的/ude1成像/vn质量/gi。/w　　/nz平板/n扫描仪/gi对/p印刷体/n文本/gi的/ude1识别率/n在/p20/nz世纪/qt90/nz年代/n就/d已经/d达到/v99%/nz以上/f，/w可谓/vocr/gi应用/gi /x迎来/v的/ude1第一个/gi高潮/n。/w当时/t最/d著名/a事件/gi是/vshi谷歌/ntc数字图书馆/nt，/w谷歌/ntc还/d申请/v了/ule图书/n扫描/gi专利/gi，/w实现/gi了/ule批量化/v的/ude1高速/b扫描/gi。/w在此期间/l，/w手写/vi字体/gi的/ude1识别/gi也/d在/p并行/vn发展/gi，/w被/pbei广泛/a /x用于/v邮件/n分拣/v、/w支票/n分类/gi、/w手写/vi表/n数字化/vn等/udeng领域/gi。/w　　/nz这样/rzv的/ude1成就/n一度/d让/v大家/rr误以为/iocr/gi技术/gi已经/d登峰造极/vl，/w但/c从/p21/nz世纪/qt开始/v，/w准确/a地/ude2说/v是/vshi自/p /x从/p2004/nz年/qt拥有/v300/nz万/nz像素/gi摄像头/gi的/ude1智能手机/nz诞生/gi之日起/ns，/w这/rzv一/nz情况/n发生/v了/ule根本/a改变/v。/w越来越/d多/a的/ude1人/n随手/d拿起/v手机/gi拍摄/v所/usuo看到/v的/ude1事物/n和/cc场景/gi，/w而/cc此类/r自然/n场景/gi中/f /x的/ude1文字识别/gi难度/n远远/d高于/v平板/n扫描仪/gi时期/n，/w即便/c是/vshi印刷/vn字体/gi，/w也/d不能/v得到/v很高/d的/ude1识别率/n，/w更/d别说/c手写体/n了/ule。/w学术界/n因此/c将/d自然/n场景/gi中的/v文字识别/gi作为/p全新/b的/ude1课题/n来/vf对待/v。/w　　/nz与此同时/c，/w云计算/gi、/w大数据/gi以及/cc通讯/gi网络/gi的/ude1快速/d发展/gi，/w实现/gi了/ule智能手机/nz的/ude124/nz小时/n在线/vn，/w前端/gi采用/v手机/gi摄像头/gi进行/vn文字/gi捕捉/v，/w后端/f可以/v对/p其/rz /x进行/vn实时/n分析/gi和/cc处理/vn，/w二者/rzv的/ude1结合/v让/vocr/gi的/ude1未来/t应用/gi模式/gi充满/v想象/v。/w因此/c，/w对/pocr/gi的/ude1研究/gi再度/d成为/v学术界/n的/ude1焦点/n，/w无论是/c前端/gi识别/gi技术/gi还是/c后端/f的/ude1关联/vn应用/gi领/v /x域/ng，/w都/d有着/v无限/b可能/v。/w微软/ntc亚洲/ns研究院/nis的/ude1研究员/nnt们/k，/w也/d非常/d有幸/v加入/v了/ule这个/rz大潮/n。/w　　/nz自然/n场景/gi下/f的/ude1文字/gi检测/gi获/v突破性/n进展/vn　　/nz自然/n场景/gi图像/gi中的/v文字识别/gi大大/d难于/vd扫描仪/gi图像/gi中的/v文字识别/gi，/w因为/c它/rr具有/v极大/a的/ude1多样性/n和/cc明显/a的/ude1不确定性/gm。/w如/v文字/gi中/f包含/v多种语言/l，/w每种/r语言/gi含有/v多/a种/q字母/gi，/w每/rz /x个/q字母/gi又/d可以/v有/vyou不同/a的/ude1大小/n、/w字体/gi、/w颜色/gi、/w亮度/n、/w对比度/n等/udeng；/w文字/gi通常/d以/p文本/gi行/ng的/ude1形式/gi存在/v，/w但/c文本/gi行/ng可能/v有/vyou不同/a的/ude1排列/gi和/cc对齐/gi方式/n，/w横向/n、/w竖向/v、/w弯曲/a都/d有可能/nz；/w /x因/p拍摄/v图像/gi的/ude1随意性/n，/w图像/gi中的/v文字/gi区域/n还/d可能会/nz产生/v变形/vi(/nz透视/vn和/cc仿射变换/gg)/nz、/w残缺/v、/w模糊/gi断裂/vi等/udeng现象/n。/w自然/n场景/gi图片/gi中的/v文字/gi多样性/n示例/gi　　/nz与/cc传统/n ocr /nz技术/gi中的/v扫描/gi文档/gi图像/gi相比/vi，/w自然/n场景/gi图像/gi的/ude1背景/n更为/d复杂/a。/w如/v文字/gi可能/v不是/c写/v在/p平面/gi上/f而是/c在/p曲面/nf上/f；/w文字/gi区域/n附近/f有/vyou非常复杂/b的/ude1纹理/n和/cc噪声/n；/w图像/gi中的/v非/b文字/gi区域/n有着/v跟/p文字/gi区域/n非常/d相/d的/ude1纹理/n，/w比如/v窗户/n、/w树叶/n、/w栅栏/n、/w砖墙/n等/udeng。/w这些/rz复杂/a背景/n会/v极大/a增加/v误检/gi率/v。/w　　/nz由于/p自然/n场景/gi下/f的/ude1文字识别/gi难度/n大/a，/w微软/ntc亚洲/ns研究院/nis团队/gi对/p相关/vn技术/gi和/cc算法/gi进行/vn了/ule针对性/n的/ude1优化/gi和/cc创新/gi，/w从/p三个方/nz面对/v文本/gi检测/gi技术/gi进行/vn了/ule改进/gi，/w并/cc取得/v突破/gi。/w通/v /x常/d，/wocr/gi识别/gi的/ude1步骤/gi可以/v分为/v两步/n：/w首先/d是/vshi文本/gi检测/gi(/nztext detection/nz)/nz，/w将/d文字/gi从/p图片/gi中/f提取/v出来/vf；/w然后/c，/w对/p文本/gi进行/vn识别/gi(/nzrecognition/nz)/nz，/w此次/rz的/ude1突破/gi主要/b是/vshi在/p文本/gi检测/gi环节/gi的/ude1两个子/nz阶段/gi。/w　　/nz阶段/gi①/nz：/w采用/v新算法/nz，/w检测/gi准确/a高效/b　　/nz一个/mq字母/gi或/c文字/gi通常/d可以/v分为/v若/c干/v个/q连通/gi区域/n，/w如/vo/nz就/d拥有/v一个/mq连通/gi区域/n，/wi/nz则/d拥有/v两/nz个/q连通/gi区域/n，/w文本/gi检测/gi首先/d要/v从/p图像/gi中/f切割/v出/vf可能/v存在/v的/ude1文字/gi，/w即/v候选/b连通/gi区域/n，/w然后/c再/d对/p其/rz进行/vn文字/gi//nz非/b文字/gi分类/gi。/w　　/nz在/p确定/v候选/b连通/gi区域/n阶段/gi，/w微软/ntc亚洲/ns研究院/nis团队/gi在/p传统/n检测/gi方法/gier/gi(/nzextremal region/nz，/w极/d区域/n)/nz和/ccmser/nz(/nzmaximally stable extremal region/nz，/w最大/gm平稳/a极/d区域/n)/nz基础/gi之上/f创新/gi地/ude2采用/v了/ule对比/gi极/d区域/ncer/nz(/nzcontrasting extremal region/nz)/nz，/wcer/nz是/vshi跟/p周围/f的/ude1背景/n有/vyou一定/b对比度/n的/ude1极/d区域/n，/w这个/rz对比度/n至少/d要强/a到/v能够/v被/pbei人/n感知/gi到/v，/w在/p低/a对比度/n的/ude1图像/gi上/f比/pmser/nz效果/gi更好/d，/w而且/c获得/v /x的/ude1候选/b连通/gi区域/n数量/n远/a小于/ver/gi，/w候选/b范围/n大大/d缩小/v，/w提高/v了/ule算法/gi的/ude1效率/gi。/w　　/nz为了/p提高/v所/usuo获得/v的/ude1候选/b连通/gi区域/n的/ude1质量/gi，/w微软/ntc亚洲/ns研究院/nis团队/gi决定/v增加/v一个/mq算法/gi环节/gi去/vf增强/vcer/nz。/w尤其/d在/p图像模/nz糊/v、/w分辨率/n低/a或者/c噪声/n较多/d时/qt，/w提取/v出来/vf的/ude1cer/nz有可能会/nz含有/v冗余/n像素/gi或者/c噪声/n，/w这些/rz冗余/n像素/gi或者/c噪声/n的/ude1存在/v会/v使得/vi后面/f的/ude1文字/gi//nz非/b文字/gi分类/gi问题/gi变得/vi更为/d复杂/a。/w　　/nz采用/v基于/p感知/gi的/ude1光照/n不变/nz(/nzperception/nz-/nzbased illuminationinvariant/nz,/nz pii/nz)/nz颜色/gi空间/n中的/v颜色/gi信息/gi去/vf增强/vcer/nz可/v算是/v此次/rz算法/gi优化/gi的/ude1另一个/nz创新/gi之举/r，/w利用/v颜色/gi信息/gi尽可能/d滤除/nzcer/nz中的/v冗余/n像素/gi或者/c噪声/n，/w从而/c得到/v color/nz-/nzenhanced cer/nz。/w该/rz颜色/gi空间/n具有/v视觉/n感知/gi一致性/gi，/w而且/c对/p光照/n不/d敏感/gi，/w更/d接近/v人/n对/p颜色/gi的/ude1判断/gi。/w受/v噪声/n影响/gi的/ude1cer/nz示例/gi　　/nz在/p实际操作/n中/f，/w并/cc不是/c每个/rcer/nz都/d需要/v通过/p颜色/gi信息/gi来/vf增强/v，/w因为/c有/vyou很/d多/acer/nz本身/rz颜色/gi均匀/a，/w没有/v噪声/n，/w尤其/d是/vshi在/p图片/gi质量/gi很高/d的/ude1时候/n。/w因此/c，/w在/p对/pcer/nz进行/vn增强/v操作/gi之前/f我们/rr会/v先/d判断/gi该/rzcer/nz是否/v需要/v增强/v操作/gi，/w以/p减少/v不必要/a的/ude1计算/gi复杂度/gi。/w对/pcer/nz的/ude1颜色/gi增强/v效果/gi示例/gi　　/nz阶段②/nz：/w创新/gi分类/gi，/w检测/gi更高/d质/ng　　/nz当/p获得/v了/ule高质量/nz的/ude1候选/b连通/gi区域/n，/w就/d需要/v对/p其中/rz的/ude1字符/gi进行/vn分辨/v，/w确定/v其/rz是否/v为/p文字/gi或非/c文字/gi，/w微软/ntc亚洲/ns研究院/nis团队/gi创新/gi地/ude2提出/v了/ule一套/nz基于/p浅层/nz神经网络/nz的/ude1文字/gi//nz非/b文字/gi分类/gi算法/gi，/w比/p以往/t的/ude1算法/gi更加/d有效/gi。/w　　/nz该/rz算法/gi根据/p文字/gi本身/rz的/ude1特性/gi采用/v分治/gi策略/gi将/d原始/a问题/gi空间/n划分/v为/p5/nz个子/n空间/n，/w每个/r子/ng空间/n对应/vi一类/b文字/gi样本/gi，/w分别/d命名/v为/plong/nz类/gi，/wthin/nz类/gi，/wfill /nz类/gi，/wsquare/nz-/nzlarge/nz类/gi和/cc square/nz-/nzsmall/nz类/gi(/nz如下/vi图/gi所示/nz)/nz，/w于是/cc每个/r候选/b连通/gi区域/n被/pbei划分/v到/v这/rzv5/nz类/gi中的/v一种/nz。/w文字/gi类/gi问题/gi空间/n划分/v示例/gi　　/nz在/p每个/r子/ng空间/n中/f，/w微软/ntc亚洲/ns研究院/nis团队/gi创新/gi地/ude2利用/v无歧义/nz学习策略/gi训练/gi一个/mq相应/vi的/ude1浅层/nz神经网络/nz，/w作为/p该子/nz空间/n的/ude1文字/gi//nz非/b文字/gi分类器/n，/w我们/rr可以/v将/d该/rz神经网络/nz看作/v是/vshi一个/mq黑盒子/n，/w在/p经过/p大量/m学习/gi之后/f，/w它/rr便/d能/v较为/d准确/a的/ude1将/d文字/gi与非/c文字/gi分类/gi。/w　　/nz每次/r分类/gi动作/gi包括/v两/nz个/q阶段/gi―/w―/w预剪枝/nz(/nzpre/nz-/nzpruning/nz)/nz阶段/gi和/cc验证/v(/nzverification/nz)/nz阶段/gi。/w在/p预剪枝/nz阶段/gi，/w分类器/n的/ude1任务/gi是/vshi尽可能/d滤除/nz /x无歧义/nz的/ude1非/b文字/gi候选/b连通/gi区域/n；/w在/p验证/v阶段/gi，/w则/d通过/p引入/v更多/ad信息/gi来/vf消除/v孤立/a连通/gi区域/n的/ude1歧义性/nz，/w从而/c进一步/d滤除/nz有/vyou歧义/n的/ude1非/b文字/gi候选/b连通/gi区域/n。/w　　/nz2014/nz年/qt8/nz月/n，/w在/p瑞典/nsf首都/n斯德哥尔摩/nsf举办/v的/ude1国际/n模式识别/gi大会/gi(/nzicpr/nz)/nz上/f，/w微软/ntc亚洲/ns研究院/nis团队/gi公布/v的/ude1研究成果/nz在/p自然/n场景/gi文字/gi检测/gi的/ude1标准/gi数据/gi集/q /x(/nzicdar/nz-/nz2013/nz测试/gi集/q)/nz上/f取得/v了/ule92.1%/nz的/ude1检测/gi精度/n和/cc92.3%/nz的/ude1召回/v率/v。/w此前/t业界/n最好/d技术/gi的/ude1检测/gi精度/n是/vshi88.5%/nz，/w而/cc召回/v率/v只有/c66.5%/nz，/w /x多年来/d这些/rz数字/gi每年/r增长/gi只有/c几/d个/q百分点/n，/w微软/ntc的/ude1技术/gi让/v自然/n场景/gi图像/gi中的/v文字/gi检测/gi实现/gi了/ule突破/gi。/w　　/nz人类/gi需求/gi牵引/vn科技/gi发展/gi走到/vf今天/t，/w智慧/gi的/ude1无限/b延伸/v决定/v了/ule世界/gi的/ude1无限/b潜能/n。/w10/nz年前/t的/ude1简单/a通讯/gi工具/gi手机/gi如今/t已/d成为/v智慧/gi生活/vn的/ude1伴侣/n，/w曾经/d只/d被/pbei扫描仪/gi应用/gi的/ude1ocr/gi技术/gi亦/d已/d焕发/v新机/n。/w随着/p研究工作/v的/ude1不断/d突破/gi和/cc智能设备/gi的/ude1推陈出新/vl，/wocr/gi的/ude1应用/gi也/d将/d充满/v无限/b机会/gi、/w无限/b可能性/gi。/w　　/nz作者简介/nz：/w　　/nz霍强/nz博士/nnt，/w微软/ntc亚洲/ns研究院/nis首席/n研究员/nnt详细/gi：/w