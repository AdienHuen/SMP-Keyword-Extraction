#读“/nz关于/p数据科学/gi，/w书上/s不曾/d提及/v的/ude1三点/nz经验/gi”/w对/p数据挖掘/gi，/w机器学习/gi方面/n的/ude1实战/gi感悟/gi
　　/nz机器学习/gi，/w数据挖掘/gi的/ude1相关/vn技术/gi书籍/gi里/f，/w总会/nis罗列/v出/vf大/a量/n的/ude1数学公式/gm和/cc计算/gi方法/gi，/w就/d好比/v烹饪/vi时/qt使用/gi的/ude1各项/r专用工具/nz，/w但/c使用/gi这些/rz工具/gi时/qt的/ude1一/nz些/q注意事项/nz或/c适用/vi场景/gi，/w以及/cc为什么/ryv要/v适用/vi这个/rz工具/gi，/w则/d讲/v的/ude1不够/a或/c根本/a没/d提/v。/w所以/c，/w即使/c看过/v数本/n相关/vn书籍/gi，/w我/rr还是/c要/v去找/v和/cc手头/n项目/gi比较/gi相/d的/ude1有/vyou实际/n案例/gi的/ude1cook/nz书/gi，/w才能/n按图索骥/vl的/ude1找到/v合适/a的/ude1分析/gi算法/gi。/w　　/nz数学/gi算法/gi，/w只要/c有心/v，/w有/vyou一定/b的/ude1功底/n，/w花/n时间/gi就/d能/v掌握/v，/w但/c为什么/ryv该/rz这么/rz做/v这么/rz做/v的/ude1原因/n，/w我/rr始终认为/i这/rzv才/d是/vshi数据挖掘/gi专家/gi的/ude1核心/n竞争力/gi所在/n。/w正好/z今天/t看/v这/rzv篇文章/n里/f讲到/v的/ude1三点/nz经验/gi，/w和/cc我/rr自己/rr对/p这/rzv方面/n的/ude1思考/gi有/vyou一定/b的/ude1重合/vi，/w所以/c在/p这里/rzs整理/gi记录/gi下/f自己/rr对应/vi的/ude1思考/gi感悟/gi，/w一方面/c可以/v方便/a以后/f查阅/v归档/vn，/w另外/c也/d希望/v和/cc同行/gi们/k交流/gi探讨/v，/w相互/d启发/vn借鉴/gi。/w　　/nz下面/f针对/gi上文/n中/f提到/v的/ude1三点/nz经验/gi一一罗列/nz：/w　　/nz1/nz、/w评价/gi方法/gi是/vshi关键/n　　/nz初学者/gi常犯/n的/ude1错误/gi就是/v仅仅/d关注/v手头/n数据/gi集/q上/f的/ude1表现/v效果/gi，/w然后/c认为/v在/p未来/t数据/gi上/f同样/d奏效/vi。/w　　/nz....../w　　/nz如果/c你/rr只/d考虑/v训练/gi集/q数据/gi，/w那么/c机器/gi很容易/nz记住/v整个/b训练/gi集/q，/w然后/c返回/v完美/a的/ude1测试/gi结果/n（/w除非/c数据/gi自相矛盾/vl）/w。/w　　/nz....../w　　/nz因此/c合适/a的/ude1评价/gi方法/gi是/vshi模拟/gi有/vyou未来/t数据/gi的/ude1场景/gi，/w把/pba数据/gi集/q一分为二/i，/w一/nz部分/n做/v训练/gi集/q，/w然后/c在/p另/rz一/nz部分/n测试/gi集/q数据/gi上/f做/v预测/gi。/w　　/nz牢记/v，/w训练/gi集/q的/ude1表现/v效果/gi并不等于/l实际/n数据集/nz的/ude1分析/gi效果/gi。/w如果/c不方便/nz获取/gi未来/t数据/gi，/w第一次/nz获取/gi训练/gi集/q数据/gi时/qt不妨/d多/a取点/nz，/w然后/c再/d根据/p数据集/nz的/ude1特征/gi设定/v自定义/nz抽取/v规则/gi，/w从/p训练/gi集里/ns抽出/v一/nz部分/n作为/p实际/n使用/gi的/ude1训练/gi集/q。/w考虑到/v某些/rz数据/gi的/ude1时间/gi特征/gi比较/gi明显/a，/w如果/c随机/b抽取/v，/w导致/gi训练/gi集/q的/ude1数据/gi大部分/n落在/v某个/rz时间段/gi内/f的话/udh，/w则/d分析/gi出来/vf的/ude1关联/vn模型/gi可能会/nz和/cc真实情况/l偏差/n很大/d。/w　　/nz2/nz、/w特征提取/gi是/vshi根本/a　　/nz它们/rr从/p足够/v的/ude1数据/gi样本/gi里/f鉴别/gi出/vf有效/gi信息/gi的/ude1本领/n很/d强大/a，/w但/c如果/c有效/gi信息/gi并不/d被/pbei包含/v其中/rz，/w或者/c不能/v用/p输入/v特征/gi的/ude1线性组合/gm所/usuo表示/v，/w它们/rr就/d没有/v了/ule用武之地/n。/w它们/rr本身/rz也/d无法/v通过/p“/w洞察/gi”/w数据/gi来/vf完成/v数据/gi精简/v这/rzv一/nz环节/gi。/w　　/nz....../w　　/nz换句话说/c，/w如果/c找到/v合适/a的/ude1特征/gi，/w数据量/n就/d能/v被/pbei大大/d缩减/v。/w　　/nz....../w　　/nz首先/d，/w你/rr必须/d确保/v完全/ad理解/gi这些/rz等价/vn算法/gi中的/v一种/nz，/w然后/c就/d可以/v一直/d用/p下去/vf了/ule。/w　　/nz....../w　　/nz其次/c，/w你/rr必须/d完全/ad掌握/v特征/gi工程/n。/w　　/nz当/p数据/gi维度/gi很/d多/a时/qt，/w如何/ryv剔除/v和/cc业务/gi需求/gi相关性/gi不大/d的/ude1维度/gi数据/gi是/vshi关键/n。/w读书/vi时/qt学习/gi数学/gi建模/gi的/ude1相关知识/gi时/qt，/w老师/gi一再强调/nz，/w在/p建立/gi模型/gi之前/f，/w一定/b要/v先/d找出/v影响/gi因子/n最大/gm的/ude1变量元素/nz，/w对应/vi实际/n需求/gi影响/gi较小/d的/ude1变量/gi，/w可以/v先略/nz过/uguo暂不/d考虑/v，/w除非/c发现/v仅/d使用/gi选取/gi的/ude1变量/gi建立/gi的/ude1模型/gi不能/v较好/d的/ude1模拟/gi实际/n情况/n时/qt，/w才/d考虑/v再/d引入/v之前/f忽略/v的/ude1新的/a变量/gi。/w的确/d是/vshi这样/rzv，/w昨天/t参加/gi腾讯云/nz的/ude1会议/gi时/qt，/w会议/gi上/f的/ude1两/nz位/q技术/gi大牛/nz也/d都/d提到/v了/ule类/gi的/ude1观点/gi，/w在/p设计/gi时/qt首先/d考虑/v最简单/nz最/d牢固/a的/ude1方案/gi，/w要/v有/vyou化繁为简/nz的/ude1能力/gi。/w脑/n科学家/nnt也/d通过/p科学实验/nz证实/v，/w我们/rr人类/gi的/ude1大脑/gi最多/ad同时/c记住/v4/nz块/q模组/nz，/w即/v在/p不/d搞砸/l的/ude1情况下/nz，/w我们/rr的/ude1大脑/gi同时/c最多/ad只能/v跟进/v处理/vn好/a4/nz件/q事情/n。/w将/d其/rz转变/v到/v数据分析/gi的/ude1评估/gi模型/gi设计/gi上/f，/w我/rr觉得/v上面/f提到/v的/ude1特征提取/gi，/w可/v加上/v不/d超过/v4/nz个/q特征/gi的/ude1原则/gi。/w如果/c你/rr设定/v的/ude1评估/gi模型/gi，/w提取/v的/ude1特征/gi数量/n超过/v4/nz个/q，/w我/rr觉得/v与/cc其/rz花/n时间/gi设计/gi公式/gi和/cc优化/gi算法/gi，/w还/d不如/v先/d想/v办法/gi砍掉/v多/a出/vf的/ude1影响/gi因子/n不大/d的/ude1特征/gi。/w　　/nz3/nz、/w时间/gi瓶颈/gi是/vshi模型/gi选择/gi，/w而非/c数据/gi集/q规模/gi　　/nz你/rr的/ude1算法/gi同样/d可能/v也/d不/d需要/v消耗/gi太多/ad时间/gi计算/gi。/w但/c你/rr需要/v花费/v大量/m时间/gi从/p原始数据/gi中/f提取/v特征/gi，/w通过/p交叉验证/gi来/vf比较/gi不同/a特征提取/gi方法/gi和/cc不同/a算法/gi参数/gi的/ude1效果/gi差异/n。/w　　/nz....../w　　/nz问题/gi归根结底/dl在于/v组合/gi项/q的/ude1爆发式/n增长/gi。/w假设/gi现在/t只有/c两/nz个/q参数/gi，/w并且/c训练/gi模型/gi和/cc在/p测试/gi集/q上/f评价/gi效果/gi（/w按照/p上述/b正确/a的/ude1评价/gi方式/n）/w需要/v大约/d一分钟/nz时间/gi。/w如果/c每个/r参数/gi有/vyou5/nz个/q候选/b，/w采取/v5/nz折/vi交叉验证/gi（/w把/pba数据/gi集分成/nz5/nz份/q，/w重复/gi训练/gi测试过程/gi5/nz次/qv，/w每次/r用/p不同/a的/ude1一份/nz数据/gi作为/p测试/gi集/q）/w，/w这/rzv意味着/v你/rr需要/v125/nz轮/qv计算/gi来/vf确定/v哪种/ry算法/gi效果/gi最好/d，/w你/rr的/ude1等待时间/gi也/d将/d是/vshi大约/d2/nz小时/n而/cc不是/c1/nz分钟/qt。/w　　/nz在/p选好/v合适/a的/ude1特征/gi，/w设计/gi完/vi分析/gi算法/gi，/w编码/gi实现/gi了/ule评估/gi验证/v程序/gi并/cc测试/gi成功/a后/f，/w我们/rr分析/gi之路/r其实/d才/d走/v了/ule一半/mq。/w后面/f还要/d使用/gi训练/gi集/q数据/gi和/cc之前/f保留/v的/ude1数据/gi对/p评估/gi公式/gi的/ude1参数/gi进行/vn微调/vn，/w可能/v数学/gi软件/gimathlab/nz//nzoctave/nz能/v帮/v我们/rr算出/vf完美/a契合/v训练/gi集/q的/ude1精准/nz参数/gi，/w但/c一旦/d加上/v保留/v数据/gi，/w这些/rz参数/gi立刻/d就/d从/p一个/mq数字/gi变成/v了/ule一个/mq范围/n。/w不管/c是否/v考虑/v偏差/n较大/d的/ude1某些/rz点/gi是否/v真实可信/l，/w各种/rz折腾/v就/d来/vf了/ule。/w