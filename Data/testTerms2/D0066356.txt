#【/w转/v自/p“/w果壳网/nz”/w微软/ntc亚洲/ns学院/nis】/w光学/gi字符识别/gp技术/gi：/w让/v电脑/gi“读/nz”懂/nz世界/gi
来源/gi：/w把/pba手机/gi摄像头/gi对准/v菜单/gi上/f的/ude1法语/nz菜名/n，/w屏幕/gi上/f实时/n显示/gi出/vf翻译/gi好/a的/ude1中文/gi菜名/n；/w批量/d扫描/gi书籍/gi，/w将/d全世界/n图书馆/nis的/ude1藏书/n转化/gi为/p电子书/gi；/w街景/n车/n游走/v于/p大街小巷/n，/w拍摄/v街景/n的/ude1同时/c也/d从/p图像/gi中/f自动/d提取/v文字/gi标识/n，/w让/v地图信息/n更/d丰富/a准确/a…/w…/w这些/rz场景/gi的/ude1背后/f，/w是/vshi一项/nz共同/d的/ude1关键技术/nz―/w―/w光学/gi字符识别/gp（/woptical character recognition/nz，/wocr/gi）/w。/w慧/ag读/v世界/gi鼠标/gi发明人/n道拉斯・恩尔巴特/nz（/wdouglas engelbart/nz）/w曾经/d针对/gi人工智能/gi的/ude1简称/v“/wai/gi”/w提出/v了/ule另一个/nz理念/gi―/w―/waugmented intelligence/nz，/w增强/v智能/gi。/w在/p他/rr看来/v，/w人/n已经/d足够/v聪明/a，/w我们/rr无需/v再/d去/vf复制/gi人类/gi，/w而是/c可以/v从/p更加/d实用/a的/ude1角度/n，/w将/d人类/gi的/ude1智能/gi进一步/d延伸/v，/w让/v机器/gi去/vf增强/v人/n的/ude1智能/gi。/w智能镜/nz就是/v这样/rzv的/ude1产品/gi：/w去/vf超市/gi的/ude1时候/n戴/v上/f一/nz副/b，/w看到/v心仪/v商品/gi上/f的/ude1文字/gi，/w自动/d搜索/gi出/vf详细信息/nz：/w生产商/nnd情况/n、/w在/p不同/a电商/gi平台/gi的/ude1价/n等等/udeng。/w让/v智能镜/nz“读/nz懂”/nz文字/gi的/ude1，/w正是/vocr/gi技术/gi。/wocr/gi本质/n上/f是/vshi利用/v光学设备/n去/vf捕获/v图像/gi，/w无论是/c今天/t的/ude1手机/gi、/w照相机/n，/w还是/c未来/t的/ude1智能/gi可/v穿戴/vn设备/gi，/w只要/c有/vyou文字/gi，/w就/d能/v去/vf认出来/v。/w设想/vn一下/m，/w在/p未来/t的/ude1工作/gi会议/gi中/f，/w只要/c手机/gi等/udeng智能设备/gi给/p会议/gi白板/nz拍照/gi，/w系统/gi便/d能/v自动识别/nz白板/nz上/f的/ude1讨论/gi内容/gi，/w分/qt检出/nz相关/vn人员/gi的/ude1后续/vn工作/gi，/w并/cc将/d待办/v事项/n自动/d存放/v到/v各自/rr的/ude1电子/gi日历/n中/f。/w在/pocr/gi技术/gi的/ude1支持/v下/f，/w这样/rzv的/ude1场景/gi将/d不是/c梦想/gi。/w微软/ntc去年/t推出/v的/ude1office lens/nz应用/gi就/d向/p梦想/gi的/ude1实现/gi迈进/vi了/ule一/nz小步/nz。/w在/p研究院/nis语音/gi团队/gi的/ude1核心/n支持/v下/f，/w这/rzv一/nz技术/gi已经/d可以/v通过/p视觉/n计算/gi技术/gi实现/gi对/p图像/gi的/ude1自动/d清理/gi，/w并/cc利用/v基于/p云端/n的/ude1ocr/gi技术/gi将/d对/p图片/gi进行/vn文字识别/gi，/w最终/d返还/v给/p用户/gi一个/mq可/v编辑/gi、/w可/v搜索/gi的/ude1数字/gi文件/gi。/w微软/ntc几年前/nz推出/v的/ude1手机/gi应用/gitranslator/nz，/w除了/p支持/v文本/gi和/cc语音/gi翻译/gi外/f，/w还/d能用/v手机/gi拍摄/v不同/a语言/gi的/ude1菜单/gi或/c指示牌/nz，/w翻译/gi结果/n立即/d浮现/vi于/p原文/n之上/f。/woffice lens/nz和/cctranslator/nz这/rzv两/nz款/q产品/gi中的/v“/w中日韩/ns”/wocr/gi核心技术/nz就/d来自/v微软/ntc亚洲/ns研究院/nis的/ude1语音/gi团队/gi。/wocr /nz（/woptical character recognition/nz，/w光学/gi字符识别/gp）/w就是/v这样/rzv的/ude1一项/nz技术/gi，/w它/rr的/ude1本质/n上/f是/vshi利用/v光学设备/n去/vf捕获/v图像/gi并/cc识别/gi文字/gi，/w将/d人/n的/ude1能力/gi延伸/v到/v机器/gi上/f。/w本文/r将/d介绍/giocr/gi技术/gi在/p移动/vn环境/n下/f面临/v的/ude1新/a挑战/gi，/w以及/cc在/p自然/n场景/gi图像/gi下/f微软/ntc研究院/nis文字识别/gi技术/gi的/ude1进展/vn。/w图片/gi来源/gi：/wresearch/nz./nzmicrosoft/nz./nzcom/nz辉煌/a与/cc挑战/giocr/gi技术/gi的/ude1应用/gi经历/gi了/ule超过/v半个世纪/nz的/ude1摸索/gi优化/gi。/w早/a在/p20/nz世纪/qt50/nz年代/n，/wibm/nz就/d开始/v利用/vocr/gi技术/gi实现/gi各类/r文档/gi的/ude1数字化/vn。/w但/c早期/f的/ude1ocr/gi设备/gi庞大/a而/cc复杂/a，/w只能/v处理/vn干净/a背景/n下/f的/ude1某种/rz特定/b的/ude1印刷/vn字体/gi。/w20/nz世纪/qt80/nz年代/n，/w平板/n扫描仪/gi的/ude1诞生/gi让/vocr/gi进入/v商用/b阶段/gi，/w设备/gi更为/d轻便/a灵巧/a，/w可以/v处理/vn的/ude1字体/gi数量/n也/d增多/v，/w但/c对/p文字/gi的/ude1背景/n要求/n仍然/d很高/d，/w需要/v很好/ad的/ude1成像/vn质量/gi才能/n保证/v效果/gi。/w到/v了/ule20/nz世纪/qt90/nz年代/n，/w平板/n扫描仪/gi对/p印刷体/n文本/gi的/ude1识别率/n就/d已经/d达到/v99%/nz以上/f，/w可谓/vocr/gi应用/gi迎来/v的/ude1第一个/gi高潮/n。/w当时/t最/d著名/a的/ude1事件/gi是/vshi谷歌/ntc数字图书馆/nt，/w谷歌/ntc还/d申请/v了/ule图书/n扫描/gi专利/gi，/w实现/gi了/ule批量化/v的/ude1高速/b扫描/gi。/w在此期间/l，/w手写/vi字体/gi的/ude1识别/gi也/d在/p并行/vn发展/gi，/w被/pbei广泛/a用于/v邮件/n分拣/v、/w支票/n分类/gi、/w手写/vi表/n数字化/vn等/udeng领域/gi。/w这样/rzv的/ude1成就/n，/w一度/d让/v大家/rr误以为/iocr/gi技术/gi已经/d登峰造极/vl，/w但/c自从/p2004/nz年/qt拥有/v300/nz万/nz像素/gi摄像头/gi的/ude1智能手机/nz诞生/gi之日起/ns，/wocr/gi的/ude1发展/gi又/d有/vyou了/ule新的/a追求/v：/w越来越/d多/a的/ude1人/n随手/d拿起/v手机/gi拍摄/v所/usuo看到/v的/ude1事物/n和/cc场景/gi，/w此类/r自然/n场景/gi中的/v文字识别/gi难度/n远远/d高于/v平板/n扫描仪/gi时期/n，/w即便/c是/vshi印刷/vn字体/gi，/w也/d不能/v得到/v很高/d的/ude1识别率/n，/w更/d别说/c手写体/n了/ule。/w学术界/n因此/c将/d自然/n场景/gi中的/v文字识别/gi作为/p全新/b的/ude1课题/n来/vf对待/v。/w与此同时/c，/w云计算/gi、/w大数据/gi以及/cc通讯/gi网络/gi的/ude1快速/d发展/gi，/w实现/gi了/ule智能手机/nz的/ude124/nz小时/n在线/vn，/w前端/gi采用/v手机/gi摄像头/gi进行/vn文字/gi捕捉/v，/w后端/f可以/v对/p其/rz进行/vn实时/n分析/gi和/cc处理/vn，/w二者/rzv的/ude1结合/v让/vocr/gi的/ude1未来/t应用/gi模式/gi充满/v想象/v。/w因此/c，/w对/pocr/gi的/ude1研究/gi再度/d成为/v学术界/n的/ude1焦点/n，/w无论是/c前端/gi识别/gi技术/gi还是/c后端/f的/ude1关联/vn应用领域/l，/w都/d有着/v无限/b可能/v。/w自然/n场景/gi下/f的/ude1文字/gi检测/gi自然/n场景/gi图像/gi中的/v文字识别/gi之所以/c大大/d难于/vd扫描仪/gi图像/gi中的/v文字识别/gi，/w是因为/c它/rr具有/v极大/a的/ude1多样性/n和/cc明显/a的/ude1不确定性/gm。/w文字/gi所属/n的/ude1语言/gi、/w字母/gi的/ude1字体/gi参数/gi、/w文本/gi行/ng的/ude1排列/gi和/cc对齐/gi方式/n等/udeng因素/gi，/w都/d影响/gi着/uzhe识别/gi的/ude1效果/gi。/w由于/p拍摄/v图像/gi的/ude1随意性/n，/w图像/gi中的/v文字/gi区域/n还/d可能会/nz产生/v变形/vi（/w透视/vn和/cc仿射变换/gg）/w、/w残缺/v、/w模糊/gi断裂/vi等/udeng现象/n。/w此外/c，/w与/cc传统/n ocr /nz技术/gi中的/v扫描/gi文档/gi图像/gi相比/vi，/w自然/n场景/gi图像/gi的/ude1背景/n也/d更为/d复杂/a。/w如/v文字/gi可能/v写/v在/p曲面/nf上/f、/w文字/gi区域/n附近/f有/vyou复杂/a的/ude1纹理/n和/cc噪声/n、/w图像/gi中的/v非/b文字/gi区域/n有/vyou跟/p文字/gi区域/n非常/d相/d的/ude1纹理/n（/w比如/v窗户/n、/w树叶/n、/w栅栏/n、/w砖墙/n）/w等等/udeng。/w这些/rz复杂/a背景/n会/v极大/a增加/v误检/gi率/v。/w通常/d，/wocr/gi识别/gi的/ude1步骤/gi可以/v分为/v两步/n：/w首先/d是/vshi文本/gi检测/gi（/wtext detection/nz）/w，/w将/d文字/gi从/p图片/gi中/f提取/v出来/vf；/w然后/c，/w对/p文本/gi进行/vn识别/gi（/wrecognition/nz）/w。/w微软/ntc亚洲/ns研究院/nis团队/gi对/p相关/vn技术/gi和/cc算法/gi进行/vn了/ule针对性/n的/ude1优化/gi和/cc创新/gi，/w对/p文本/gi检测/gi环节/gi进行/vn了/ule改进/gi。/w文本/gi检测/gi首先/d要/v从/p图像/gi中/f切割/v出/vf可能/v存在/v的/ude1文字/gi，/w即/v“/w候选/b连通/gi区域/n”/w，/w然后/c再/d对/p其/rz进行/vn文字/gi//nz非/b文字/gi分类/gi。/w一个/mq字母/gi或/c文字/gi通常/d可以/v分为/v若/c干/v个/q连通/gi区域/n，/w如/v字母/gi“/wo/nz”/w就/d只有/c一个/mq连通/gi区域/n，/w“/wi/nz”/w则/d拥有/v两/nz个/q连通/gi区域/n。/w在/p确定/v候选/b连通/gi区域/n阶段/gi，/w我们/rr创新/gi地/ude2采用/v了/ule对比/gi极/d区域/ncer/nz（/wcontrasting extremal region/nz）/w，/w选取/gi跟/p周围/f的/ude1背景/n有/vyou一定/b对比度/n的/ude1极/d区域/n，/w通过/p大幅/d缩小/v候选/b范围/n，/w提高/v了/ule算法/gi的/ude1效率/gi。/w受/v噪声/n影响/gi的/ude1cer/nz示例/gi。/w图片/gi来源/gi：/w霍强/nz由于/p在/p图像模/nz糊/v、/w分辨率/n低/a或者/c噪声/n较多/d时/qt，/w提取/v出来/vf的/ude1cer/nz有可能会/nz含有/v冗余/n像素/gi或者/c噪声/n，/w这些/rz冗余/n像素/gi或者/c噪声/n的/ude1存在/v会/v使得/vi后面/f的/ude1文字/gi//nz非/b文字/gi分类/gi问题/gi变得/vi更为/d复杂/a。/w为了/p提高/v所/usuo获得/v的/ude1候选/b连通/gi区域/n的/ude1质量/gi，/w微软/ntc亚洲/ns研究院/nis团队/gi决定/v增加/v一个/mq算法/gi环节/gi去/vf增强/vcer/nz。/w我们/rr利用/v图像/gi的/ude1颜色/gi信息/gi尽可能/d地/ude2滤除/nzcer/nz中的/v冗余/n像素/gi或者/c噪声/n，/w得到/v具有/v视觉/n感知/gi一致性/gi的/ude1颜色/gi空间/n。/w这/rzv一空间/nz对/p光照/n不/d敏感/gi，/w更/d接近/v人/n对/p颜色/gi的/ude1判断/gi。/w算法/gi提取/v出来/vf的/ude1候选/b连通/gi区域/n结果/n示例/gi。/w图片/gi来源/gi：/w霍强/nz当/p系统/gi获得/v了/ule高质量/nz的/ude1候选/b连通/gi区域/n，/w就/d需要/v对/p其中/rz的/ude1字符/gi进行/vn分辨/v，/w确定/v其/rz是否/v为/p文字/gi或非/c文字/gi。/w微软/ntc亚洲/ns研究院/nis团队/gi提出/v了/ule一套/nz基于/p浅层/nz神经网络/nz的/ude1文字/gi//nz非/b文字/gi分类/gi算法/gi，/w比/p以往/t的/ude1算法/gi更加/d有效/gi。/w这个/rz算法/gi根据/p文字/gi本身/rz的/ude1特性/gi采用/v分治/gi策略/gi将/d原始/a问题/gi空间/n划分/v为/p5/nz个子/n空间/n，/w每个/r子/ng空间/n对应/vi一类/b文字/gi样本/gi，/w每个/r候选/b连通/gi区域/n被/pbei划分/v到/v这/rzv5/nz类/gi中的/v一种/nz。/w在/p每个/r子/ng空间/n中/f，/w都/d有/vyou一个/mq相应/vi的/ude1浅层/nz神经网络/nz作为/p该子/nz空间/n的/ude1文字/gi//nz非/b文字/gi分类器/n―/w―/w我们/rr可以/v将/d该/rz神经网络/nz看作/v是/vshi一个/mq黑盒子/n，/w在/p经过/p大量/m学习/gi之后/f，/w它/rr便/d能/v较为/d准确/a的/ude1将/d文字/gi与非/c文字/gi分类/gi。/w文字/gi类/gi问题/gi空间/n划分/v示例/gi在/p每个/r子/ng空间/n中/f，/w微软/ntc亚洲/ns研究院/nis团队/gi利用/v无歧义/nz学习策略/gi训练/gi一个/mq相应/vi的/ude1浅层/nz神经网络/nz，/w作为/p该子/nz空间/n的/ude1文字/gi//nz非/b文字/gi分类器/n，/w我们/rr可以/v将/d该/rz神经网络/nz看作/v是/vshi一个/mq黑盒子/n，/w在/p经过/p大量/m学习/gi之后/f，/w它/rr便/d能/v较为/d准确/a的/ude1将/d文字/gi与非/c文字/gi分类/gi。/w每次/r分类/gi动作/gi包括/v两/nz个/q阶段/gi―/w―/w预剪枝/nz（/wpre/nz-/nzpruning/nz）/w阶段/gi和/cc验证/v（/wverification/nz）/w阶段/gi。/w在/p预剪枝/nz阶段/gi，/w分类器/n的/ude1任务/gi是/vshi尽可能/d滤除/nz无歧义/nz的/ude1非/b文字/gi候选/b连通/gi区域/n；/w在/p验证/v阶段/gi，/w则/d通过/p引入/v更多/ad信息/gi来/vf消除/v孤立/a连通/gi区域/n的/ude1歧义性/nz，/w从而/c进一步/d滤除/nz有/vyou歧义/n的/ude1非/b文字/gi候选/b连通/gi区域/n。/w文字/gi类/gi问题/gi空间/n划分/v示例/gi。/w图片/gi来源/gi：/w霍强/nz这些/rz改进/gi大大/d增强/v了/uleocr/gi在/p自然/n场景/gi中的/v识别/gi本领/n。/w之前/f，/w在/p自然/n场景/gi文字/gi检测/gi的/ude1标准/gi数据/gi集/q进行/vn测试/gi，/w业界/n最好/d的/ude1技术/gi所能/v达到/v的/ude1检测/gi精度/n是/vshi88.5%/nz，/w而/cc召回/v率/v只有/c66.5%。/nz而/cc在/p2014/nz年/qt8/nz月/n，/w微软/ntc亚洲/ns研究院/nis团队/gi在/p瑞典/nsf首都/n斯德哥尔摩/nsf举办/v的/ude1国际/n模式识别/gi大会/gi（/wicpr/nz）/w上/f进行/vn的/ude1自然/n场景/gi文字/gi检测/gi测试/gi中/f取得/v了/ule92.1%/nz的/ude1检测/gi精度/n和/cc92.3%/nz的/ude1召回/v率/v。/w随着/p研究工作/v的/ude1不断/d突破/gi，/wocr/gi必定/d还/d会/v焕发/v新机/n，/w衍生/vn出/vf更多/ad振奋人心/vl的/ude1应用/gi。/w（/w编辑/gi：/wcalo/nz）/w应用前景/gi分析/gi人类/gi需求/gi牵引/vn科技/gi发展/gi走到/vf今天/t，/w智慧/gi的/ude1无限/b延伸/v决定/v了/ule世界/gi的/ude1无限/b潜能/n。/w10/nz年前/t的/ude1简单/a通讯/gi工具/gi手机/gi如今/t已/d成为/v智慧/gi生活/vn的/ude1伴侣/n，/w曾经/d只/d被/pbei扫描仪/gi应用/gi的/ude1ocr/gi技术/gi亦/d已/d焕发/v新机/n。/w随着/pocr/gi研究工作/v的/ude1不断/d突破/gi，/w云计算/gi、/w大数据/gi以及/cc通讯/gi网络/gi的/ude1快速/d发展/gi，/w以及/cc智能镜/nz、/w可/v穿戴/vn设备/gi等/udeng智能设备/gi的/ude1推陈出新/vl，/wocr/gi的/ude1应用/gi也/d将/d充满/v无限/b机会/gi、/w无限/b可能性/gi。/w我们/rr也/d可以/v设想/vn一下/mocr/gi在/p未来/t工作/gi中的/v应用场景/gi：/w每次/r工作/gi会议/gi后/f，/w无需/v再/d把/pba白板/nz上/f的/ude1讨论/gi内容/gi抄写/v下来/vf，/w然后/c群发/v邮件/n布置任务/n，/w前端/gi只要/c将/d白板/nz用/p手机/gi等/udeng智能设备/gi拍照/gi留存/v，/w后端/f可以/v对/p其/rz进行/vn实时/n分析/gi和/cc处理/vn，/w系统/gi便/d能/v自动识别/nz并/cc分/qt检出/nz相关/vn人员/gi的/ude1后续/vn工作/gi，/w并/cc将/d待办/v事项/n自动/d存放/v到/v各自/rr的/ude1电子/gi日历/n中/f。/w事实上/bl，/w基于/p微软/ntc亚洲/ns研究院/nis的/ude1ocr/gi核心技术/nz，/w微软/ntc前/f不久/d推出/v的/ude1office lens/nz应用/gi，/w已经/d可以/v通过/p视觉/n计算/gi技术/gi自动/d对/p图像/gi进行/vn清理/gi并/cc把/pba它/rr保存/gi到/vonenote/nz，/w而/cconenote/nz中/f基于/p云端/n的/ude1ocr/gi技术/gi将/d对/p图片/gi进行/vn文字识别/gi，/w随后/d用户/gi就/d可以/v拥有/v一个/mq可/v编辑/gi、/w可/v搜索/gi的/ude1数字/gi文件/gi，/w这/rzv为/p上述/b未来/t应用场景/gi打下/v了/ule基础/gi。/w作者简介/nz：/w霍强/nz博士/nnt，/w微软/ntc亚洲/ns研究院/nis首席/n研究员/nnt