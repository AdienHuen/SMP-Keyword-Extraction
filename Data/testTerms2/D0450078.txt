#台湾/ns国立/b大学/gi机器学习/gi基石/n./nz听课/vi笔记/gi（/w第九/nz讲/v）/w：/wLinear Regression/nz
台湾/ns国立/b大学/gi机器学习/gi基石/n./nz听课/vi笔记/gi（/w第九/nz讲/v）/w：/wlinear regression/nz（/w线性回归/gi）/w1/nz、/w线性回归/gi问题/gi例如/v，/w信用卡/gi额度/n预测/gi问题/gi：/w特征/gi是/vshi用户/gi的/ude1信息/gi（/w年龄/n，/w性别/n，/w年薪/n，/w当前/t债务/n，/w.../w）/w，/w我们/rr要/v预测/gi可以/v给/p该/rz客户/n多/a大/a的/ude1信用/gi额度/n。/w /x这样/rzv的/ude1问题/gi就是/v回归/gi问题/gi。/w目标/giy /nz是/vshi实数/n空间/nr/nz。/w线性回归/gi假设/gi的/ude1思想/gi是/vshi：/w寻找/v这样/rzv的/ude1直线/n//nz平面/gi//nz超平面/gm，/w使得/vi输入/v数据/gi的/ude1残差/nz最小/a。/w通常/d采用/v的/ude1error measure /nz是/vshisquared error/nz:/w2/nz、/w线性回归/gi算法/gisquared error /nz的/ude1矩阵/gi表示/v：/wein /nz是/vshi连续/gi、/w可/v微/ag的/ude1、/w凸函数/gm，/w可以/v通过/p偏微/nz分求/nz极/d的/ude1方法/gi来/vf求/v参数/gi向量/giw/nz。/w由于/p是/vshi凸函数/gm，/w所以/c其/rz最小/a就是/v其/rz极小/d。/w求得/vein/nz(/nzw/nz)/nz /x的/ude1偏微分/gm：/w上面/f分/qt两/nz种/q情况/n来/vf求解/giw/nz。/w当/p(/nzx/nz^/nzt/nz)/nz*/nzx/nz(/nzx /nz的/ude1转置/gm乘以/vx/nz)/nz /x可/v逆时/nz，/w可以/v通过/p矩阵/gi运算/gi直接/ad求得/vw/nz；/w不可逆/gp时/qt，/w直观/a来看/u情况/n就/d没/d这么/rz简单/a。/w实际上/d，/w无论/c哪种/ry情况/n，/w我们/rr都/d可以/v很容易/nz得到/v结果/n。/w因为/c许多现成/nz的/ude1机器学习/gi//nz数学库/nz帮/v我们/rr处理/vn好/a了/ule这个/rz问题/gi，/w只要/c我们/rr直接/ad调用/gi相应/vi的/ude1计算/gi函数/gi即可/v。/w有些/rz库/n中/f把/pba这种/r广义/n求/v逆/vg矩阵/gi运算/gi成为/v pseudo/nz-/nzinverse/nz。/w到/v此/rzs，/w我们/rr可以/v总结线性/nz回归/gi算法/gi的/ude1步骤/gi（/w非常简单/nz清晰/a）/w：/w3/nz、/w线性回归/gi是/vshi一个/mq“/w学习/gi算法/gi”/w /x吗/y？/w我们/rr在/p这/rzv通过/p数学/gi来/vf证明/v：/w最后/f得到/v：/w4/nz、/w线性回归/gi与/cc线性/gi分类器/n比较/gi一下/m线性/gi分类/gi与/cc线性回归/gi：/w之所以/c能够/v通过/p线程/gi回归/gi的/ude1方法/gi来/vf进行/vn二分类/nz，/w是/vshi由于/p回归/gi的/ude1squared error /nz是/vshi分类/gi的/ude10/nz//nz1/nz error /nz的/ude1上界/n，/w我们/rr通过/p优化/gisquared error/nz，/w一定/b程度/n上/f也/d能/v得到/v不错/a的/ude1分类/gi结果/n；/w或者/c，/w更好/d的/ude1选择/gi是/vshi，/w将/d回归/gi方法/gi得到/v的/ude1w /nz作为/p二分类/nz模型/gi的/ude1初始/bw /nz。/w线性回归/gi与/cc线性/gi分类/gi有/vyou相同之处/nz，/w我们/rr以后/f求解/gi线性/gi分类/gi时/qt，/w可以/v先/d求/v线性回归/gi，/w看看/v它/rr的/ude1结果/n。/w最后/f，/w再/d用/p线性/gi分类/gi进行/vn进一步/d求解/gi相关/vn问题/gi。/w这样/rzv，/w我们/rr就/d基本/a搞定/v了/ule线性回归/gi。/w#/nz