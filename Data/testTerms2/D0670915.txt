#机器学习/gi实战/gipython/gi版/nLogistic/nz回归/gi
基于/plogistic /nz回归/gi和/ccsigmoid/nz函数/gi的/ude1分类/gi首先/d我们/rr要/v了解/vsigmoid/nz函数/gi是/vshi什么样/ryv的/ude1函数/gi，/w再者/c这个/rzlogistic/gi回归/gi模型/gi和/cc这个/rz函数/gi的/ude1联系/gi。/w主要/b内容/gi可以/v参见/v李航/nr的/ude1《/w统计学习方法/gi》/w第六章/nz有/vyou详细/gi的/ude1讲解/gi，/w我/rr是/vshi看/v了/ule里面/f的/ude1内容/gi在/p对应/vi着/uzhe看/v机器学习/gi实战/gi中的/v代码/gi学习/gi的/ude1。/w二项/nz逻辑斯蒂/nz回归/gi主要/b还是/c在于/v确定/v对应/vi特征/gi的/ude1权重/nz，/w来/vf得到/vz/nz=/nz w/nz*/nzx/nz，/w从而/c根据/p模型/gi获得/v输出/gi分类/gi的/ude1y/nz。/w权重/nz的/ude1获得/v是/vshi通过/p梯度下降/gi发来/v做/v的/ude1，/w梯度方向/gp总是/d只想/v函数/gi上升/vi的/ude1方向/gi，/w所以/c我们/rr要/v找到/v最佳/z的/ude1拟合系数/nz，/w就是/v特征/gi的/ude1权重/nz，/w我们/rr就/d需要/v沿/p梯度方向/gp不断/d近/a。/w梯度下降/gi法/n可以/v参见/v最优化/gm学习/gi方法/gi。/w在/p这里/rzs还是/c主要/b是/vshi看懂/nz代码/gi。。。/w。/w。/w训练/gi算法/gi分析/gi数据/gix/nz2/nz /x=/nz(/nz /x-/nz w/nz0/nz*/nz1/nz /x-/nzw/nz1/nz*/nzx/nz1/nz)/nz//nzw/nz2/nz;/nz所以/c代码/gi才/d会/v这样/rzv写/v。/w我们/rr知道/v偏执/a变量/gi对应/vi的/ude1特征/gi都/d设/v为了/p1./nz这/rzv两/nz个/q函数/gi只是/d在/p细节/gi上/f优化/gi算法/gi，/w降低/v运算/gi次数/gi，/w尽量/d提高/v准确度/n。/w