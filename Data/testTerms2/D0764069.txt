#《/w统计学习方法/gi，/w李航/nr》/w：/w2/nz、/w感知机/gb模型/gi
1/nz）/w概述/gi2/nz）/w感知器/nz模型/gi3/nz）/w感知器/nz策略/gi4/nz）/w感知器/nz算法/gi1/nz）/w概述/gi /x感知机/gb学习/gi旨在/v求出/v将/d训练数据/gi集/q进行/vn线性/gi划分/v的/ude1分类/gi超平面/gm（/w线性/gi不可分/nz的/ude1训练/gi样例/nz不能/v被/pbei感知器/nz学习/gi）/w。/w感知机/gb模型/gi是/vshi神经网络/nz和/cc支持/v向量/gi机/ng的/ude1基础/gi。/w下面/f分别/d从/p感知机/gb学习/gi的/ude1模型/gi、/w策略/gi和/cc算法三/nz个/q方面/n来/vf介绍/gi。/w2/nz）/w感知器/nz模型/gi f/nz(/nzx/nz)/nz=/nz sign/nz(/nzw/nz*/nzxb/nz)/nz。/w其中/rz，/wx/nz为/p输入/v向量/gi，/wsign/nz为/p符号/gi函数/gi。/ww/nz为/p权向量/nz，/wb/nz为/p偏置/gp，/w求/v感知机/gb模型/gi即/v求/v模型/gi参数/giw/nz和/ccb/nz。/w3/nz）/w感知器/nz策略/gi耗费/v函数/gi定义/gi为/pl/nz(/nzw/nz,/nzb/nz)/nz=/nz-/nz(/nz y/nz1/nz*/nz(/nzw/nz*/nzx/nz1/nzb/nz)/nz.../wym/nz*/nz(/nzw/nz*/nzxmb/nz)/nz /x)/nz，/w自己/rr想/v清楚/a为什么/ryv这样/rzv定义/gi耗费/v函数/gi。/w4/nz）/w感知器/nz算法/gi极/d小化/nz耗费/v函数/gil/nz(/nzw/nz,/nzb/nz)/nz的/ude1梯度/gi是/vshi对/pw/nz和/ccb/nz求/v偏导/nz，/w即/v：/w所以/c，/w感知机/gb学习/gi算法/gi如下/vi：/w该/rz算法/gi的/ude1收敛性/nz和/cc对偶/n形式/gi参考/gi原/b书/gi。/w