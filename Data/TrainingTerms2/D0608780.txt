#读书笔记/nz：/w机器学习/gi实战/gi(/nz3/nz)/nz―/w―/w章/q4/nz的/ude1朴素贝叶斯/gi分类/gi代码/gi和/cc个人/n理解/gi与/cc注释/gi
简单/a介绍/gi下/f朴素贝叶斯/gi分类/gi原理/gi：/w /x首先/d要/v知道/v贝叶斯/nrf公式/gi：/w  /x贝叶斯/nrf定理/gi是/vshi一种/nz用/p先验概率/gm推断/v后验/nz概率/gi:/w在/pb/nz出现/v的/ude1前提/n下/f,/nza/nz出现/v的/ude1概率/gi等于/va/nz出现/v的/ude1前提/n下/fb/nz出现/v的/ude1概率/gi乘以/va/nz出现/v的/ude1概率/gi再/d除以/vb/nz出现/v的/ude1概率/gi。/w通过/p联系/gia/nz与/ccb/nz,/nz计算/gi从/p一个/mq事件/gi产生/v另一事件/nz的/ude1概率/gi,/nz即/v从/p结果/n上溯/vi原/b。/w /x而/cc这/rzv一/nz章/q的/ude1代码/gi，/w是/vshi通过/p简单/a的/ude1词袋/nz模式/gi，/w通过/p计算/gi训练/gi集中/v该/rz事件/gi对应/vi的/ude1每个/r词/n出现/v的/ude1先验概率/gm，/w来/vf推断出/nz文章/gi中/f每个/r词/n对应/vi的/ude1事件/gi概率/gi，/w对/p同类/n概率/gi求和/vi，/w以/p最大/gm概率/gi的/ude1事件/gi作为/p预测/gi事件/gi。/w /x从/p实际/n使用/gi角度/n来说/uls，/w可以/v用/p的/ude1trick/nz调优/gi方法/gi有/vyou：/w去/vf停词/nz（/w去/vf噪/vg）/w，/w指数/n映射/gi（/w避免/v越界/vi）/w，/w分子/gi分母/n同/p加/v1/nz（/w避免出现/v0/nz概率/gi）/w，/w《/w数学/gi之/uzhi美/b》/w中/f提到/v的/ude1二关联词/nz袋/ng模式/gi（/w原著/n中/f本章/r内容/gi都/d是/vshi假设/gi为/p独立/a事件/gi）/w，/w以及/cc对/p未/d发生/v事件/gi给予/vn一定/b的/ude1概率/gi估算/v（/w图灵机/gi模型/gi？/w记不清/vl了/ule，/w应该/v也/d是/vshi以前/f在/p《/w数学/gi之/uzhi美/b》/w中/f看到/v的/ude1调优/gi方法/gi）/w /x代码/gi就/d不加/v注释/gi了/ule，/w大多/d是/vshi循环/gi遍历/gi和/ccset/nz去/vf重/a，/w累积/v求和/vi，/w概率/gi计算/gi